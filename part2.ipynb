{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from lora import LoRA\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Load the fine-tuned LoRA model\n",
    "lora_a = LoRA(model)\n",
    "lora_a.load_pretrained('lora_finetuned_gpt2_a')\n",
    "\n",
    "lora_b = LoRA(model)\n",
    "lora_b.load_pretrained('lora_finetuned_gpt2_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage import sage\n",
    "\n",
    "def get_target_response(question: list, model, tokenizer):\n",
    "    inputs = tokenizer(question, return_tensors='pt')\n",
    "    outputs = model.generate(**inputs)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_training_data(questions, model_a, model_b, tokenizer, threshold):\n",
    "    training_data = []\n",
    "\n",
    "    for question in questions:\n",
    "        a_response = get_target_response(question, model_a, tokenizer)\n",
    "        b_response = get_target_response(question, model_b, tokenizer)\n",
    "        \n",
    "        a_score = sage.score(question, a_response, use_rots=True)\n",
    "        b_score = sage.score(question, b_response, use_rots=True)\n",
    "        \n",
    "        if a_score > threshold:\n",
    "            training_data.append((question, a_response))\n",
    "        elif b_score > threshold:\n",
    "            training_data.append((question, b_response))\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['What makes us human?']\n",
    "threshold = 0.8\n",
    "training_data = create_training_data(questions, lora_a, lora_b, tokenizer, threshold)\n",
    "\n",
    "# Train the model\n",
    "# we need to alternate the training between the two models\n",
    "# TODO how to alternate?\n",
    "# need to set some kind of threshold for when to switch\n",
    "lora_a.train(training_data)\n",
    "# lora_b.train(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a.save_pretrained('lora_finetuned_gpt2_p2_a')\n",
    "lora_b.save_pretrained('lora_finetuned_gpt2_p2_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should have our own test set to evaluate the model\n",
    "# human evaluation maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
